system_prompt: null
first_prompt: null
user_prompt: null
assistant_response: null
abbreviations: null
model: "Deepseek V3"
endpoint: null
temperature: 0.8
max_tokens: 100000
trim_history: true
use_summary: true
include_previous_part_when_summarizing: True
include_previous_part_when_rewriting: True
history_path: "story.md"
summary_path: "story_summary.md"
prompts_path: "prompts.md"
folder_path: ""
separator: "\n----\n"
interrupt_flag: false
write_interval: 1.0
debug: false
print_messages: true
include_reasoning: true
history_prefix: "**Previous text parts for reference:**"
print_reasoning: true