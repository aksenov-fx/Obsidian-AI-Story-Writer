{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tested with Python 3.12\n",
    "\n",
    "from _includes import config, models\n",
    "from _includes.StoryGenerator.Chat import Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.first_prompt = f'''\n",
    "**Story summary:**\n",
    "This is a story about a Red Hood\n",
    "\n",
    "**Characters:**\n",
    "Red Hood - a little girl\n",
    "Wolf - a big bad wolf\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These letters in user prompt's text will be replaced with full names\n",
    "\n",
    "config.abbreviations.update({\n",
    "    'R': 'Red Hood', \n",
    "    'W': 'Wolf'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a scene - Deepseek R1\n",
    "Chat.write_scene(models['Deepseek R1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom prompt - will not have a pre-prompt and post-prompt instructions\n",
    "config.user_prompt = '''\n",
    "Offer several options for story continuation in a form of story cards\n",
    "'''\n",
    "Chat.custom_prompt(models['Deepseek R1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a scene - Qwen 72b\n",
    "Chat.write_scene(models['Qwen 72b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine a part of the story according to guidelines in the user_prompt and prompt_vars\n",
    "# #refine tag will be replaced with text defined in _includes/Settings/abbreviations.yaml\n",
    "\n",
    "config.user_prompt = f'''\n",
    "Change story tense from third person to first person\n",
    "For instance: \"Red Hood stood\" -> \"I stood\"\n",
    "\n",
    "#refine\n",
    "'''\n",
    "\n",
    "Chat.rewrite(models['Deepseek V3'], part=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite the story beginning from specified part number\n",
    "\n",
    "config.user_prompt = f'''\n",
    "Enrich the story part with dialogue\n",
    "'''\n",
    "\n",
    "Chat.rewrite_parts(models['Deepseek V3'], part=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regenerate a part of the story\n",
    "\n",
    "config.user_prompt = f'''\n",
    "Mother gives Little Red Riding Hood a basket of food.\n",
    "'''\n",
    "\n",
    "config.print_output = True\n",
    "Chat.regenenerate(models['Deepseek V3'], part=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a part to the story after a specified part\n",
    "\n",
    "config.user_prompt = f'''\n",
    "Mother gives Little Red Riding Hood a basket of food.\n",
    "'''\n",
    "\n",
    "Chat.add_part(models['Deepseek V3'], part=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the story\n",
    "# Summarized parts will replace the original parts in the prompt\n",
    "# This will help reduce the number of tokens in the prompt\n",
    "# Adding or deleting story parts in the middle of the story will require a new summary or a manual summary update\n",
    "\n",
    "config.use_summary = True\n",
    "config.include_previous_part_when_summarizing = True # If False, only the current part text will be included in API request\n",
    "\n",
    "Chat.summarize(models['Deepseek V3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize new story parts that were not yet summarized\n",
    "Chat.update_summary(models['Deepseek V3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove last response from md file\n",
    "Chat.remove_last_response()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Act 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.user_prompt = '''\n",
    "Mother gives Little Red Riding Hood a basket of food.\n",
    "Mother tells R to take the basket to her grandmother.\n",
    "R walks through the forest.\n",
    "'''\n",
    "\n",
    "Chat.write_scene(models['Deepseek R1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.user_prompt = '''\n",
    "A wolf approaches Little Red Riding Hood and asks where she is going.\n",
    "R tells the wolf she is visiting her grandmother.\n",
    "The W suggests she pick flowers for her grandmother.\n",
    "'''\n",
    "\n",
    "Chat.write_scene(models['Deepseek V3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.user_prompt = '''\n",
    "\n",
    "'''\n",
    "Chat.write_scene(models['Deepseek R1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
