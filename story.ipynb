{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tested with Python 3.12.2\n",
    "\n",
    "from _includes import Chat, ChatHistory, config, models, vars\n",
    "config.history_path=\"story.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.first_prompt = f'''\n",
    "**Story summary:**\n",
    "This is a story about a red hood\n",
    "\n",
    "**Characters:**\n",
    "Red Hood - a little girl\n",
    "Wolf - big bad wolf\n",
    "\n",
    "**Guidelines**\n",
    "{vars.guidelines}\n",
    "\n",
    "Start the story with the following events:\n",
    "Mother gives Little Red Riding Hood a basket of food.\n",
    "Mother tells Little Red Riding Hood to take the basket to her grandmother.\n",
    "Little Red Riding Hood walks through the forest.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a scene - Deepseek R1\n",
    "Chat.write_scene(models['deepseek'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a scene - Qwen 72B\n",
    "Chat.write_scene(models['qwen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom prompt - will not have a pre-prompt and post-prompt instructions\n",
    "config.user_prompt = '''\n",
    "Summarize the story\n",
    "'''\n",
    "Chat.custom_prompt(models['qwen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove last response from md file\n",
    "ChatHistory.remove_last_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert assistant response into md file\n",
    "ChatHistory.insert(config.assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset assistant response variable\n",
    "config.assistant_response=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a window with function buttons (optional)\n",
    "from _includes.chat_ui import Chat_UI\n",
    "config.print_messages = False\n",
    "Chat_UI.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Act 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell below will define the beginning of the assistant response, unless the md file already has a response  \n",
    "\n",
    "The file is considered to have a response if:  \n",
    "1. It has some content and does not have a separator\n",
    "2. It has a separator and some text after the separator\n",
    "\n",
    "If the provider API works correctly, the provider will continue the assistant response instead of starting a new one  \n",
    "For non-thinking models - thinking will be removed from the request  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.assistant_response='''\n",
    "<think>\n",
    "Okay, I need to write a story based on the given summary and guidelines. \n",
    "</think>\n",
    "\n",
    "The Red Riding Hood\n",
    "\n",
    "Beneath the ash-gold haze of an autumn noon, the cottage exhaled cinnamon steam from its thatched roof.\n",
    "'''\n",
    "\n",
    "Chat.write_scene(models['deepseek'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Act 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.user_prompt = '''\n",
    "A wolf approaches Little Red Riding Hood and asks where she is going.\n",
    "Little Red Riding Hood tells the wolf she is visiting her grandmother.\n",
    "The wolf suggests she pick flowers for her grandmother.\n",
    "Little Red Riding Hood stops to pick flowers.\n",
    "'''\n",
    "\n",
    "Chat.write_scene(models['qwen'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
