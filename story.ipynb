{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tested with Python 3.12\n",
    "\n",
    "from _includes import Chat, ChatHistory, config, models, vars\n",
    "\n",
    "# File settings\n",
    "config.history_path=\"story.md\"\n",
    "config.separator='----'\n",
    "\n",
    "# Reasoning settings\n",
    "    # Note: old reasoning will be removed automatically from the request - it does not have to be removed from the file\n",
    "    # Note: different inference providers output reasoning differently, which may result in <think> tags missing in the output\n",
    "    # Note: some providers do not allow to define reasoning. These providers can be excluded in openrouter web ui settings.\n",
    "\n",
    "config.include_reasoning = True # Output model reasoning to md file\n",
    "config.reasoning_header = '### Reasoning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.first_prompt = f'''\n",
    "**Story summary:**\n",
    "This is a story about a Red Hood\n",
    "\n",
    "**Characters:**\n",
    "Red Hood - a little girl\n",
    "Wolf - a big bad wolf\n",
    "\n",
    "**Guidelines**\n",
    "{vars.guidelines}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a scene - Deepseek R1\n",
    "Chat.write_scene(models['Deepseek R1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a scene - Qwen 72b\n",
    "Chat.write_scene(models['Qwen 72b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom prompt - will not have a pre-prompt and post-prompt instructions\n",
    "config.user_prompt = '''\n",
    "Offer several options for story continuation in a form of story cards\n",
    "'''\n",
    "Chat.custom_prompt(models['Deepseek R1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove last response from md file\n",
    "ChatHistory.remove_last_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert text to md file\n",
    "text = '### Part '\n",
    "ChatHistory.insert(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a window with function buttons (optional)\n",
    "from _includes.chat_ui import Chat_UI\n",
    "Chat_UI.start()\n",
    "config.print_messages = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Act 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.user_prompt = '''\n",
    "Mother gives Little Red Riding Hood a basket of food.\n",
    "Mother tells Little Red Riding Hood to take the basket to her grandmother.\n",
    "Little Red Riding Hood walks through the forest.\n",
    "'''\n",
    "Chat.write_scene(models['Deepseek R1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.user_prompt = '''\n",
    "A wolf approaches Little Red Riding Hood and asks where she is going.\n",
    "Little Red Riding Hood tells the wolf she is visiting her grandmother.\n",
    "The wolf suggests she pick flowers for her grandmother.\n",
    "Little Red Riding Hood stops to pick flowers.\n",
    "'''\n",
    "Chat.write_scene(models['Qwen 72b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.user_prompt = '''\n",
    "\n",
    "'''\n",
    "Chat.write_scene(models['Qwen 72b'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
